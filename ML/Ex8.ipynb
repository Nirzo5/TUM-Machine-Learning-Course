{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed259b4-71ee-41b7-851b-7e666f94c7a6",
   "metadata": {},
   "source": [
    "# Pre-Procces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7eb2f80-81f1-49fe-9a92-5c6d5a8b3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wine DF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load red wine data\n",
    "red_df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "\n",
    "# Load white wine data\n",
    "white_df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Add a new column to each to mark the wine type\n",
    "red_df['wine_type'] = 'red'\n",
    "white_df['wine_type'] = 'white'\n",
    "\n",
    "# Combine red and white DataFrames\n",
    "D2 = pd.concat([red_df, white_df], ignore_index=True)\n",
    "\n",
    "# Apply one-hot encoding to 'wine_type' WITHOUT dropping the first category\n",
    "D2 = pd.get_dummies(D2, columns=['wine_type'])\n",
    "\n",
    "D2['wine_type_red'] = D2['wine_type_red'].astype(int)\n",
    "D2 ['wine_type_white'] = D2['wine_type_white'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10f7d584-354d-44d8-a054-89953b71af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(df):\n",
    "    print(\"=== Checking DataFrame ===\")\n",
    "    \n",
    "    # Check for nulls\n",
    "    nulls = df.isnull().sum()\n",
    "    print(\"\\nNull values per column:\")\n",
    "    print(nulls[nulls > 0] if nulls.sum() > 0 else \"No nulls found\")\n",
    "    \n",
    "    # Check for sparse data (defined here as >90% same value)\n",
    "    print(\"\\nChecking for sparse columns (>=90% same value):\")\n",
    "    for col in df.columns:\n",
    "        top_freq = df[col].value_counts(normalize=True).max()\n",
    "        if top_freq >= 0.9:\n",
    "            print(f\"Column '{col}' is sparse (top value frequency: {top_freq:.2f})\")\n",
    "    \n",
    "    # Check if all columns are numeric\n",
    "    non_numeric = df.select_dtypes(exclude=[np.number]).columns\n",
    "    if len(non_numeric) > 0:\n",
    "        print(\"\\nNon-numeric columns detected:\")\n",
    "        print(non_numeric)\n",
    "    else:\n",
    "        print(\"\\nAll columns are numeric\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bab2d79-a91d-4289-91fa-ec1a014e4561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the column names based on the structure you just showed\n",
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "# Read the .data file\n",
    "D1 = pd.read_csv(\"iris.data\", names=columns)\n",
    "\n",
    "# Show the first few rows\n",
    "print(D1.head())\n",
    "print(D1['class'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac85fe8-1e2c-4570-8419-c0273f50be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1['class'] = D1['class'].map({\n",
    "    'Iris-setosa': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-virginica': 2\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c014c5c-6646-4f34-a2cf-4c597f11b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking DataFrame ===\n",
      "\n",
      "Null values per column:\n",
      "No nulls found\n",
      "\n",
      "Checking for sparse columns (>=90% same value):\n",
      "\n",
      "All columns are numeric\n",
      "------------------------------------\n",
      "=== Checking DataFrame ===\n",
      "\n",
      "Null values per column:\n",
      "No nulls found\n",
      "\n",
      "Checking for sparse columns (>=90% same value):\n",
      "\n",
      "All columns are numeric\n"
     ]
    }
   ],
   "source": [
    "check_df(D1)\n",
    "print ( \"------------------------------------\")\n",
    "check_df(D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c85b3-539d-4371-9918-c535c7666dc9",
   "metadata": {},
   "source": [
    "# Exercise 1: Implement K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32b4a429-6de9-4062-bd65-ff2fa571efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_test_split(data, test_size=0.3, shuffle=True):\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle the data\n",
    "    \n",
    "    split_index = int((1 - test_size) * len(data))\n",
    "    train_data = data.iloc[:split_index]\n",
    "    test_data = data.iloc[split_index:]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "D1_train,D1_test = train_test_split(D1)\n",
    "D2_train,D2_test = train_test_split(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ee416fa-4c15-469b-ac6a-9eaea8bd36e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a58a22e-4617-4fe2-abe9-7c8b70bedc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality', 'wine_type_red',\n",
       "       'wine_type_white'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d1ee1c-b33c-4749-a7b2-86a23818a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For D1 (Iris)\n",
    "X_D1 = D1.drop(columns='class').values\n",
    "y_D1 = D1['class'].values\n",
    "\n",
    "# For D2 (Wine)\n",
    "X_D2 = D2.drop(columns='quality').values\n",
    "y_D2 = D2['quality'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74e1a1cd-b332-4a9c-b384-96a64c2ee54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement similarity measures\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e192f92-4edf-4e3e-ac76-45e3a23340dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_neighbors(X_train, y_train, query_point, k):\n",
    "    distances = np.array([euclidean_distance(query_point, x) for x in X_train])\n",
    "    nearest_indices = distances.argsort()[:k]  # indices of the k smallest distances\n",
    "    nearest_labels = y_train[nearest_indices]\n",
    "    \n",
    "    return nearest_indices, nearest_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f8ea77b-5e5c-449f-8136-cd90140e58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_neighbors(nearest_labels, task_type='classification', all_labels=None, return_prob=False):\n",
    "    if task_type == 'classification':\n",
    "        unique, counts = np.unique(nearest_labels, return_counts=True)\n",
    "\n",
    "        if return_prob:\n",
    "            # Match class probabilities to the full label set\n",
    "            classes = np.unique(all_labels)\n",
    "            prob_vector = np.zeros(len(classes))\n",
    "            for i, cls in enumerate(classes):\n",
    "                if cls in unique:\n",
    "                    prob_vector[i] = counts[np.where(unique == cls)[0][0]]\n",
    "            prob_vector = prob_vector / len(nearest_labels)\n",
    "            return prob_vector, classes\n",
    "        else:\n",
    "            # Just return majority class\n",
    "            return unique[np.argmax(counts)]\n",
    "\n",
    "    elif task_type == 'regression':\n",
    "        return np.mean(nearest_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d34b4940-ed49-4e58-af84-4b552764a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, task_type='classification'):\n",
    "    if task_type == 'classification':\n",
    "        accuracy = np.mean(y_true == y_pred)\n",
    "        return accuracy  # Higher is better\n",
    "    elif task_type == 'regression':\n",
    "        mse = np.mean((y_true - y_pred) ** 2)\n",
    "        return mse  # Lower is better\n",
    "    else:\n",
    "        raise ValueError(\"task_type must be either 'classification' or 'regression'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea2089d7-5a23-47dd-8886-cbfe6adcce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6541538461538461\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Split data\n",
    "def train_test_split(data, test_size=0.3, shuffle=True):\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    split_idx = int((1 - test_size) * len(data))\n",
    "    return data.iloc[:split_idx], data.iloc[split_idx:]\n",
    "\n",
    "# 2. Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# 3. K nearest neighbors\n",
    "def get_k_nearest_neighbors(X_train, y_train, query_point, k):\n",
    "    distances = np.array([euclidean_distance(query_point, x) for x in X_train])\n",
    "    nearest_indices = distances.argsort()[:k]\n",
    "    nearest_labels = y_train[nearest_indices]\n",
    "    return nearest_indices, nearest_labels\n",
    "\n",
    "# 4. Prediction function\n",
    "def predict_from_neighbors(nearest_labels, task_type='regression'):\n",
    "    if task_type == 'classification':\n",
    "        unique, counts = np.unique(nearest_labels, return_counts=True)\n",
    "        return unique[np.argmax(counts)]\n",
    "    elif task_type == 'regression':\n",
    "        return np.mean(nearest_labels)\n",
    "\n",
    "# 5. Evaluation\n",
    "def evaluate_predictions(y_true, y_pred, task_type='regression'):\n",
    "    if task_type == 'classification':\n",
    "        return np.mean(y_true == y_pred)\n",
    "    elif task_type == 'regression':\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Assume D2 is already loaded\n",
    "D2_train, D2_test = train_test_split(D2, test_size=0.3)\n",
    "\n",
    "X_train = D2_train.drop(columns='quality').values\n",
    "y_train = D2_train['quality'].values\n",
    "X_test = D2_test.drop(columns='quality').values\n",
    "y_test = D2_test['quality'].values\n",
    "\n",
    "# Run KNN for regression\n",
    "k = 5\n",
    "y_preds = []\n",
    "\n",
    "for query in X_test:\n",
    "    _, labels = get_k_nearest_neighbors(X_train, y_train, query, k)\n",
    "    pred = predict_from_neighbors(labels, task_type='regression')\n",
    "    y_preds.append(pred)\n",
    "\n",
    "y_preds = np.array(y_preds)\n",
    "\n",
    "# Evaluate\n",
    "mse = evaluate_predictions(y_test, y_preds, task_type='regression')\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162113c-82d8-46a6-adce-72a3c465d502",
   "metadata": {},
   "source": [
    "# Brief conclusion \n",
    "To evaluate the KNN model on the wine dataset (D2), we used Mean Squared Error (MSE) as the quality metric since this is a regression task. After splitting the data into training and test sets, the model achieved an MSE of approximately 0.65. This indicates that, on average, the predicted wine quality scores deviate by less than one point from the actual scores, suggesting a reasonably accurate performance for a simple KNN approach.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2f120-abc8-4655-b966-a2b5a6e58e0e",
   "metadata": {},
   "source": [
    "# Exercise 2: Optimize and Compare KNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ddc6a-d299-4224-8eda-8c1764286185",
   "metadata": {},
   "source": [
    "### Part A: Determine the Optimal Value of K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3726e2-70e9-49dd-b1a0-c681ff79610b",
   "metadata": {},
   "source": [
    "1)  To choose the optimal value of \n",
    "ùêæ\n",
    "K in KNN, we use a validation-based approach. We evaluate the model's performance for multiple \n",
    "ùêæ\n",
    "K values using a chosen error metric (e.g., accuracy for classification or mean squared error for regression). The \n",
    "ùêæ\n",
    "K that results in the lowest error (or highest accuracy) on the validation set is selected as the optimal value. This helps balance underfitting (large \n",
    "ùêæ\n",
    "K) and overfitting (small \n",
    "ùêæ\n",
    ")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "830c6c52-d086-4193-a1b8-247c552c7715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use D1 (iris) ‚Äî classification\n",
    "D1_train, D1_val = train_test_split(D1, test_size=0.3)\n",
    "\n",
    "X_train = D1_train.drop(columns='class').values\n",
    "y_train = D1_train['class'].values\n",
    "X_val = D1_val.drop(columns='class').values\n",
    "y_val = D1_val['class'].values\n",
    "\n",
    "# implement the criterion\n",
    "def find_best_k(X_train, y_train, X_val, y_val, k_values, task_type='classification'):\n",
    "    errors = []\n",
    "    for k in k_values:\n",
    "        preds = []\n",
    "        for query in X_val:\n",
    "            _, labels = get_k_nearest_neighbors(X_train, y_train, query, k)\n",
    "            pred = predict_from_neighbors(labels, task_type=task_type)\n",
    "            preds.append(pred)\n",
    "        preds = np.array(preds)\n",
    "        error = evaluate_predictions(y_val, preds, task_type=task_type)\n",
    "        errors.append(error)\n",
    "    return errors\n",
    "\n",
    "# Run for a range of k values\n",
    "k_values = range(1, 21)\n",
    "errors = find_best_k(X_train, y_train, X_val, y_val, k_values, task_type='classification')\n",
    "\n",
    "# Plot\n",
    "plt.plot(k_values, errors, marker='o')\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"KNN Classification: Accuracy vs K\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ebc23-9c23-4193-80db-fc7d6cfd1088",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "The accuracy remains consistently high (around 97.9%) for values of \n",
    "ùêæ\n",
    "K from 1 to 18, and then drops when \n",
    "ùêæ\n",
    "K becomes too large. This suggests that a small \n",
    "ùêæ\n",
    "K, such as 3 or 5, is optimal for this classification task. Testing values of \n",
    "ùêæ\n",
    "K beyond 20 is unnecessary in this case, as the trend already shows declining performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9830d-695e-4724-baea-faf8494e938d",
   "metadata": {},
   "source": [
    "# Part B: Compare KNN Algorithm with Tree-Based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a129d67-f74d-4d44-a0ef-bd2481a81bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 - Iris Dataset\n",
      "KNN Best Params: {'n_neighbors': 1}\n",
      "KNN Accuracy: 1.0\n",
      "Decision Tree Best Params: {'max_depth': 4, 'min_samples_split': 10}\n",
      "Decision Tree Accuracy: 1.0\n",
      "\n",
      "D2 - Wine Dataset (Simplified)\n",
      "KNN Best Params: {'n_neighbors': 1}\n",
      "KNN Accuracy: 0.5933333333333334\n",
      "Decision Tree Best Params: {'max_depth': None, 'min_samples_split': 2}\n",
      "Decision Tree Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# D1 - Iris dataset\n",
    "X1 = D1.drop(columns='class').values\n",
    "y1 = D1['class'].values\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "\n",
    "# KNN Grid Search for D1\n",
    "knn_params = {'n_neighbors': list(range(1, 21))}\n",
    "knn = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n",
    "knn.fit(X1_train, y1_train)\n",
    "\n",
    "# Decision Tree Grid Search for D1\n",
    "tree_params = {'max_depth': [2, 3, 4, 5, 10, None], 'min_samples_split': [2, 5, 10]}\n",
    "tree = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_params, cv=5)\n",
    "tree.fit(X1_train, y1_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "knn_pred = knn.predict(X1_test)\n",
    "tree_pred = tree.predict(X1_test)\n",
    "\n",
    "print(\"D1 - Iris Dataset\")\n",
    "print(\"KNN Best Params:\", knn.best_params_)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y1_test, knn_pred))\n",
    "print(\"Decision Tree Best Params:\", tree.best_params_)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y1_test, tree_pred))\n",
    "\n",
    "# D2 - Wine dataset (simplified classification)\n",
    "def simplify_quality(quality):\n",
    "    if quality <= 5:\n",
    "        return 'low'\n",
    "    elif quality == 6:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "D2_simplified = D2.copy()\n",
    "D2_simplified['quality'] = D2_simplified['quality'].apply(simplify_quality)\n",
    "\n",
    "X2 = D2_simplified.drop(columns='quality').values\n",
    "y2 = D2_simplified['quality'].values\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# KNN Grid Search for D2\n",
    "knn2 = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n",
    "knn2.fit(X2_train, y2_train)\n",
    "\n",
    "# Decision Tree Grid Search for D2\n",
    "tree2 = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_params, cv=5)\n",
    "tree2.fit(X2_train, y2_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "knn2_pred = knn2.predict(X2_test)\n",
    "tree2_pred = tree2.predict(X2_test)\n",
    "\n",
    "print(\"\\nD2 - Wine Dataset (Simplified)\")\n",
    "print(\"KNN Best Params:\", knn2.best_params_)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y2_test, knn2_pred))\n",
    "print(\"Decision Tree Best Params:\", tree2.best_params_)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y2_test, tree2_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b3a27-a8ae-434d-90e7-81acef07b07f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "To enable classification on the wine dataset (D2), which originally had a numerical \"quality\" score, we converted the values into categorical labels: 'low' (‚â§5), 'medium' (=6), and 'high' (‚â•7). This allowed us to apply KNN and Decision Tree classifiers. After hyperparameter tuning with GridSearchCV, we found that both models performed well on the Iris dataset (D1), with high accuracy. On the simplified wine dataset, performance was slightly lower, reflecting the more complex and less balanced nature of the data. Overall, both algorithms showed competitive results, with Decision Trees slightly outperforming KNN in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee223b-1e8e-4970-8338-1b37542de2d7",
   "metadata": {},
   "source": [
    "# Exercise 2: Recommender system using similarity measures "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397e564-c916-4b64-98bc-498b262aaa4b",
   "metadata": {},
   "source": [
    "## For MovieLens 100K dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "621bc106-b032-440a-a366-02d772cdd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "\n",
    "# Load ratings\n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('u.data', sep='\\t', names=columns, usecols=columns[:3])\n",
    "\n",
    "# Create user-item matrix\n",
    "user_item = ratings.pivot(index='user_id', columns='item_id', values='rating').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dd014b0-9c12-4a40-9924-764ce3fe152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the ratings\n",
    "shuffled = ratings.sample(frac=1, random_state=42)\n",
    "cut = int(0.8 * len(shuffled))\n",
    "train_ratings = shuffled.iloc[:cut]\n",
    "test_ratings = shuffled.iloc[cut:]\n",
    "train_matrix = train_ratings.pivot(index='user_id', columns='item_id', values='rating')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b768c0a-e339-45fe-9ac9-a25ff8f66a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    # Compare only where both have ratings\n",
    "    mask = (~np.isnan(a)) & (~np.isnan(b))\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0  # no common ratings\n",
    "    a_masked = a[mask]\n",
    "    b_masked = b[mask]\n",
    "    return np.dot(a_masked, b_masked) / (np.linalg.norm(a_masked) * np.linalg.norm(b_masked))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c93ed252-aae7-4d9d-bf22-27b68e2e83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User KNN\n",
    "def predict_user(user, item, k):\n",
    "    if item not in train_matrix.columns or user not in train_matrix.index:\n",
    "        return train_matrix.stack().mean()  # fallback to global average\n",
    "\n",
    "    target_vector = train_matrix.loc[user].values\n",
    "    similarities = []\n",
    "\n",
    "    for other_user in train_matrix.index:\n",
    "        if other_user == user or pd.isna(train_matrix.loc[other_user, item]):\n",
    "            continue\n",
    "        sim = cosine_sim(target_vector, train_matrix.loc[other_user].values)\n",
    "        similarities.append((sim, train_matrix.loc[other_user, item]))\n",
    "\n",
    "    if not similarities:\n",
    "        return train_matrix.stack().mean()  # fallback if no neighbors found\n",
    "\n",
    "    # Take top K neighbors\n",
    "    similarities = sorted(similarities, key=lambda x: x[0], reverse=True)[:k]\n",
    "\n",
    "    # Weighted average of ratings\n",
    "    num = sum(sim * rating for sim, rating in similarities)\n",
    "    den = sum(abs(sim) for sim, _ in similarities)\n",
    "    return num / den if den != 0 else np.mean([r for _, r in similarities])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8d3e40e-a292-408d-8cc0-b5f7cfa5cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse(preds, actuals):\n",
    "    return sqrt(np.nanmean((np.array(preds) - np.array(actuals)) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f6ed6e0-9059-4319-a3f6-8e56ffa55fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random sample of 1000 test ratings\n",
    "sample_test = test_ratings.sample(n=1000, random_state=42)\n",
    "\n",
    "def evaluate_user_knn_sample(k):\n",
    "    preds = []\n",
    "    actuals = []\n",
    "\n",
    "    for _, row in sample_test.iterrows():\n",
    "        user, item, true_rating = row['user_id'], row['item_id'], row['rating']\n",
    "        pred_rating = predict_user(user, item, k)\n",
    "        preds.append(pred_rating)\n",
    "        actuals.append(true_rating)\n",
    "\n",
    "    return rmse(preds, actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6341b0cb-1fc9-40fd-a8e2-113e7606826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-KNN RMSE (k=10): 1.0481\n"
     ]
    }
   ],
   "source": [
    "rmse_score = evaluate_user_knn_sample(k=10)\n",
    "print(f\"User-KNN RMSE (k=10): {rmse_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8bb5484-7dec-4a49-8190-b917d21409a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1 ‚Üí RMSE = 1.3696\n",
      "K = 5 ‚Üí RMSE = 1.0984\n",
      "K = 10 ‚Üí RMSE = 1.0481\n",
      "K = 20 ‚Üí RMSE = 1.0224\n",
      "K = 30 ‚Üí RMSE = 1.0165\n",
      "K = 40 ‚Üí RMSE = 1.0170\n",
      "K = 50 ‚Üí RMSE = 1.0168\n"
     ]
    }
   ],
   "source": [
    "#optimizing HyperParameter\n",
    "k_values = [1, 5, 10, 20, 30, 40, 50]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    rmse_k = evaluate_user_knn_sample(k)\n",
    "    results[k] = rmse_k\n",
    "    print(f\"K = {k} ‚Üí RMSE = {rmse_k:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b545cc8d-3058-496d-aaeb-bfecc4fd47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item- KNN\n",
    "def predict_item(user, item, k):\n",
    "    if user not in train_matrix.index or item not in train_matrix.columns:\n",
    "        return train_matrix.stack().mean()  # fallback\n",
    "\n",
    "    sims = []\n",
    "\n",
    "    for other_item in train_matrix.columns:\n",
    "        if other_item == item or pd.isna(train_matrix.loc[user, other_item]):\n",
    "            continue\n",
    "        sim = cosine_sim(train_matrix[item].values, train_matrix[other_item].values)\n",
    "        sims.append((sim, train_matrix.loc[user, other_item]))\n",
    "\n",
    "    if not sims:\n",
    "        return train_matrix.stack().mean()\n",
    "\n",
    "    # Take top K similar items\n",
    "    sims = sorted(sims, key=lambda x: x[0], reverse=True)[:k]\n",
    "\n",
    "    num = sum(sim * rating for sim, rating in sims)\n",
    "    den = sum(abs(sim) for sim, _ in sims)\n",
    "    return num / den if den != 0 else np.mean([r for _, r in sims])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e398332-06a6-48e5-92b8-45c4efdc2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_item_knn_sample(k):\n",
    "    preds = []\n",
    "    actuals = []\n",
    "\n",
    "    for _, row in sample_test.iterrows():\n",
    "        user, item, true_rating = row['user_id'], row['item_id'], row['rating']\n",
    "        pred_rating = predict_item(user, item, k)\n",
    "        preds.append(pred_rating)\n",
    "        actuals.append(true_rating)\n",
    "\n",
    "    return rmse(preds, actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71de0c77-496c-40f7-a2bd-5789c8bf9466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1 ‚Üí Item-KNN RMSE = 1.5861\n",
      "K = 5 ‚Üí Item-KNN RMSE = 1.2042\n",
      "K = 10 ‚Üí Item-KNN RMSE = 1.1071\n",
      "K = 20 ‚Üí Item-KNN RMSE = 1.0539\n",
      "K = 30 ‚Üí Item-KNN RMSE = 1.0436\n",
      "K = 40 ‚Üí Item-KNN RMSE = 1.0363\n",
      "K = 50 ‚Üí Item-KNN RMSE = 1.0334\n"
     ]
    }
   ],
   "source": [
    "k_values = [1, 5, 10, 20, 30, 40, 50]\n",
    "item_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    rmse_k = evaluate_item_knn_sample(k)\n",
    "    item_results[k] = rmse_k\n",
    "    print(f\"K = {k} ‚Üí Item-KNN RMSE = {rmse_k:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c51d1-0ee1-4cb6-bb04-c33c4e5d77a3",
   "metadata": {},
   "source": [
    "# Results\n",
    "| Method   | K  | Test RMSE |\n",
    "| -------- | -- | --------- |\n",
    "| User-KNN | 1  | 1.3696    |\n",
    "| User-KNN | 5  | 1.0984    |\n",
    "| User-KNN | 10 | 1.0481    |\n",
    "| User-KNN | 20 | 1.0224    |\n",
    "| User-KNN | 30 | 1.0165    |\n",
    "| User-KNN | 40 | 1.0170    |\n",
    "| User-KNN | 50 | 1.0168    |\n",
    "| Item-KNN | 1  | 1.5861    |\n",
    "| Item-KNN | 5  | 1.2042    |\n",
    "| Item-KNN | 10 | 1.1071    |\n",
    "| Item-KNN | 20 | 1.0539    |\n",
    "| Item-KNN | 30 | 1.0436    |\n",
    "| Item-KNN | 40 | 1.0363    |\n",
    "| Item-KNN | 50 | 1.0334    |\n",
    "\n",
    "We tested User-KNN and Item-KNN using cosine similarity with different values of K on a sample of 1,000 test ratings. As K increased, both methods showed better prediction accuracy, and the RMSE values gradually decreased. Item-KNN consistently performed better than User-KNN, achieving the lowest RMSE of 1.0334 at K = 50. This suggests that item-based similarity may be more effective for rating prediction in this dataset.\n",
    "\n",
    "Notes:\n",
    "1.  Compared to MyMediaLite benchmarks (RMSE ~0.94‚Äì0.97), our best score (1.0334) is close, considering the basic implementation and sample size used.\n",
    "2.  I had to reduce the sample size becasue my PC could not handle the computation of the full DF\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60c4f550-53ff-4d32-a4f7-a5de17d5f56f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb1024-b61c-4a73-84d3-0406e882a444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
